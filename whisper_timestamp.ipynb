{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOjkJqrtXcLZOaCAEoLpGSB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArielMobileLab/Archive/blob/main/whisper_timestamp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install whisper-timestamped"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iUT5XajkX4m",
        "outputId": "ad2c4449-5a6e-416f-c5fe-1dbd24a4daa4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting whisper-timestamped\n",
            "  Downloading whisper_timestamped-1.15.4-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from whisper-timestamped) (3.0.10)\n",
            "Collecting dtw-python (from whisper-timestamped)\n",
            "  Downloading dtw_python-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.5/770.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai-whisper (from whisper-timestamped)\n",
            "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from dtw-python->whisper-timestamped) (1.11.4)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from dtw-python->whisper-timestamped) (1.25.2)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper->whisper-timestamped) (2.3.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper->whisper-timestamped) (0.58.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper->whisper-timestamped) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper->whisper-timestamped) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper->whisper-timestamped) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper->whisper-timestamped)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper->whisper-timestamped) (3.14.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper->whisper-timestamped) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper->whisper-timestamped) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper->whisper-timestamped) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper->whisper-timestamped) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper->whisper-timestamped) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper->whisper-timestamped) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper->whisper-timestamped) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper->whisper-timestamped) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper->whisper-timestamped)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper->whisper-timestamped) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper->whisper-timestamped) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801358 sha256=cf6b426fd6d64b85d1d5a9b5242f271093c818508532f43e46a689d108d10f34\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, dtw-python, nvidia-cusolver-cu12, openai-whisper, whisper-timestamped\n",
            "Successfully installed dtw-python-1.5.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0 whisper-timestamped-1.15.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1: Mount Google Drive and Set Up Folders"
      ],
      "metadata": {
        "id": "-ckfcupAjZEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)  # This will prompt for authorization\n",
        "\n",
        "# Define paths for audio files and transcription files\n",
        "audio_folder_path = \"/content/drive/MyDrive/Whisper/Audio/\"\n",
        "transcription_folder_path = \"/content/drive/MyDrive/Whisper/Transcriptions/\"\n",
        "\n",
        "# Create \"Transcriptions\" folder if it doesn't exist\n",
        "if not os.path.exists(transcription_folder_path):\n",
        "    os.makedirs(transcription_folder_path)\n",
        "\n",
        "print(\"Google Drive mounted successfully.\")\n",
        "print(f\"Audio files will be read from: {audio_folder_path}\")\n",
        "print(f\"Transcription files will be saved to: {transcription_folder_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J797EGpJgeK",
        "outputId": "5d2ebcf9-3c0a-4bdc-aea4-7319430536ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully.\n",
            "Audio files will be read from: /content/drive/MyDrive/Whisper/Audio/\n",
            "Transcription files will be saved to: /content/drive/MyDrive/Whisper/Transcriptions/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2: List Audio Files"
      ],
      "metadata": {
        "id": "7BSvh2D0jjjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all the file paths in the folder\n",
        "audio_files = [os.path.join(audio_folder_path, file) for file in os.listdir(audio_folder_path) if file.endswith(('.wav', '.mp3', '.m4a'))]\n",
        "\n",
        "# Print the file paths\n",
        "for p in audio_files:\n",
        "    print(p)\n",
        "\n",
        "# Print the total number of audio files\n",
        "print(f\"\\033[1mThere are {len(audio_files)} audio files to transcribe.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q-FMc4djHAq",
        "outputId": "e4abe16a-f91f-4e13-8e36-55b4ba56df3e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Whisper/Audio/recording.wav\n",
            "\u001b[1mThere are 1 audio files to transcribe.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3: Install Whisper Timestamp"
      ],
      "metadata": {
        "id": "JmM10mS9j8mE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4: Define the Transcription Function"
      ],
      "metadata": {
        "id": "6s8nN4HLkMAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import subprocess\n",
        "import json\n",
        "\n",
        "# Function to transcribe using a specific model and adjust the start time of the first word\n",
        "def transcribe_and_adjust_timestamps(audio_file, transcription_folder_path):\n",
        "    base_name = os.path.basename(audio_file)\n",
        "\n",
        "    # Run Whisper with medium model\n",
        "    medium_command = f\"whisper_timestamped \\\"{audio_file}\\\" --model medium --language he --output_dir \\\"{transcription_folder_path}\\\"\"\n",
        "    subprocess.run(medium_command, shell=True, check=True)\n",
        "\n",
        "    # Determine the name of the output file for the medium model\n",
        "    medium_output_file = os.path.join(transcription_folder_path, base_name + \".words.json\")\n",
        "\n",
        "    # Read the medium model output to get the start time of the first word\n",
        "    with open(medium_output_file, 'r') as f:\n",
        "        medium_result = json.load(f)\n",
        "    start_time_first_word = medium_result['segments'][0]['words'][0]['start']\n",
        "\n",
        "    # Run Whisper with large model\n",
        "    large_command = f\"whisper_timestamped \\\"{audio_file}\\\" --model large --language he --output_dir \\\"{transcription_folder_path}\\\"\"\n",
        "    subprocess.run(large_command, shell=True, check=True)\n",
        "\n",
        "    # Determine the name of the output file for the large model\n",
        "    large_output_file = os.path.join(transcription_folder_path, base_name + \".words.json\")\n",
        "\n",
        "    # Read the large model output and adjust the start time of the first word\n",
        "    with open(large_output_file, 'r') as f:\n",
        "        large_result = json.load(f)\n",
        "    if large_result['segments']:\n",
        "      large_result['segments'][0]['start'] += start_time_first_word\n",
        "\n",
        "\n",
        "    # Adjust only the first word's start time in the first segment\n",
        "    if large_result['segments'] and large_result['segments'][0]['words']:\n",
        "        large_result['segments'][0]['words'][0]['start'] += start_time_first_word\n",
        "\n",
        "    # Save the adjusted transcription to a new JSON file\n",
        "    adjusted_output_file = os.path.join(transcription_folder_path, base_name + \"_adjusted.words.json\")\n",
        "    with open(adjusted_output_file, 'w') as f:\n",
        "        json.dump(large_result, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"Transcription for {audio_file} saved to {adjusted_output_file}\")\n"
      ],
      "metadata": {
        "id": "NE4IRqnTrW5P"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process each audio file\n",
        "for audio_file in audio_files:\n",
        "    transcribe_and_adjust_timestamps(audio_file, transcription_folder_path)\n",
        "\n",
        "print(f\"\\033[1mProcessing completed. Transcriptions saved to {transcription_folder_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7b_wYfsJghC",
        "outputId": "a7eb283a-5a6c-4804-d621-5422041387f8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription for /content/drive/MyDrive/Whisper/Audio/recording.wav saved to /content/drive/MyDrive/Whisper/Transcriptions/recording.wav_adjusted.words.json\n",
            "\u001b[1mProcessing completed. Transcriptions saved to /content/drive/MyDrive/Whisper/Transcriptions/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## combine data"
      ],
      "metadata": {
        "id": "IjMUN5orw1f0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define the calculate_recording_time function\n",
        "def calculate_recording_time(recording_data):\n",
        "    # Extracting World_time values and converting them to datetime objects\n",
        "    world_times = [datetime.strptime(segment['World_time'], '%H:%M:%S.%f') for segment in recording_data]\n",
        "\n",
        "    # Calculating the recording time by subtracting the first World_time from each subsequent World_time\n",
        "    recording_times = [(time - world_times[0]).total_seconds() for time in world_times]\n",
        "\n",
        "    return recording_times\n"
      ],
      "metadata": {
        "id": "U_i0-P64JgkH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file paths\n",
        "adjusted_output_file = \"/content/drive/MyDrive/Whisper/Transcriptions/recording.wav_adjusted.words.json\"\n",
        "recording_data_file = \"/content/drive/MyDrive/Whisper/Transcriptions/recording_data.json\"\n",
        "\n",
        "# Load data from the adjusted transcription JSON file\n",
        "with open(adjusted_output_file, \"r\") as file:\n",
        "    recording = json.load(file)\n",
        "\n",
        "# Load data from recording_data.json\n",
        "with open(recording_data_file, \"r\") as file:\n",
        "    recording_data = json.load(file)\n",
        "\n",
        "# Initialize list to store segments\n",
        "segments = []\n",
        "\n",
        "# Calculate recording times\n",
        "recording_times = calculate_recording_time(recording_data)\n",
        "\n",
        "# Iterate through each segment in recording data\n",
        "for segment in recording['segments']:\n",
        "    # Extract start time from the segment\n",
        "    start_time = segment['start']\n",
        "\n",
        "    # Calculate duration of the segment\n",
        "    duration = segment['end'] - segment['start']\n",
        "\n",
        "    # Flag to check if a match is found\n",
        "    match_found = False\n",
        "\n",
        "    # Iterate through segments in modified data\n",
        "    for i, audio_segment in enumerate(recording_data):\n",
        "        # Check if start time matches world time\n",
        "        if abs(start_time - recording_times[i]) < 1:  # Adjust the tolerance as needed\n",
        "            # Extract world time from the audio segment\n",
        "            world_time = audio_segment[\"World_time\"]\n",
        "\n",
        "            # Extract other relevant information\n",
        "            simulation_time = audio_segment[\"simulation_time\"]\n",
        "\n",
        "            # Calculate end simulation time\n",
        "            end_simulation_time = simulation_time + duration\n",
        "\n",
        "            # Create a dictionary for the segment\n",
        "            segment_info = {\n",
        "                \"text\": segment[\"text\"],\n",
        "                \"start_time\": str(timedelta(seconds=start_time)),\n",
        "                \"end_time\": str(timedelta(seconds=start_time + duration)),\n",
        "                \"world_time\": world_time,\n",
        "                \"simulation_time\": simulation_time,\n",
        "                \"end_simulation_time\": end_simulation_time\n",
        "            }\n",
        "\n",
        "            # Append segment to list of segments\n",
        "            segments.append(segment_info)\n",
        "            match_found = True\n",
        "            break  # Break the loop if a matching segment is found\n",
        "\n",
        "    # Check if a match was found for the current segment\n",
        "    if not match_found:\n",
        "        print(f\"No matching record time found for start time: {start_time}\")\n",
        "\n",
        "# Write the segments to a new JSON file\n",
        "combined_output_file = \"/content/drive/MyDrive/Whisper/Transcriptions/combined_segments.json\"\n",
        "with open(combined_output_file, \"w\") as file:\n",
        "    json.dump(segments, file, indent=4)\n",
        "\n",
        "print(f\"Combined segments saved to {combined_output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Pg-knT_Jgp8",
        "outputId": "82415968-7711-416d-b1c4-32a983894700"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined segments saved to /content/drive/MyDrive/Whisper/Transcriptions/combined_segments.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and display the combined output file\n",
        "combined_output_file = \"/content/drive/MyDrive/Whisper/Transcriptions/combined_segments.json\"\n",
        "\n",
        "with open(combined_output_file, \"r\") as file:\n",
        "    combined_segments = json.load(file)\n",
        "\n",
        "# Display the contents of the combined output file\n",
        "print(json.dumps(combined_segments, indent=4, ensure_ascii=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1E6RKRCmGr4",
        "outputId": "1785b78e-5f99-472f-92b2-f1afa3db65da"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"text\": \" אחד אני נוסע\",\n",
            "        \"start_time\": \"0:00:02.560000\",\n",
            "        \"end_time\": \"0:00:05.940000\",\n",
            "        \"world_time\": \"15:38:37.168\",\n",
            "        \"simulation_time\": 251.33334644153032,\n",
            "        \"end_simulation_time\": 254.71334644153032\n",
            "    },\n",
            "    {\n",
            "        \"text\": \" שמאלה\",\n",
            "        \"start_time\": \"0:00:07.980000\",\n",
            "        \"end_time\": \"0:00:08.760000\",\n",
            "        \"world_time\": \"15:38:42.587\",\n",
            "        \"simulation_time\": 255.0666799695743,\n",
            "        \"end_simulation_time\": 255.8466799695743\n",
            "    },\n",
            "    {\n",
            "        \"text\": \" חמישים ושלוש\",\n",
            "        \"start_time\": \"0:00:10.120000\",\n",
            "        \"end_time\": \"0:00:11.400000\",\n",
            "        \"world_time\": \"15:38:44.729\",\n",
            "        \"simulation_time\": 256.56668004780624,\n",
            "        \"end_simulation_time\": 257.8466800478062\n",
            "    },\n",
            "    {\n",
            "        \"text\": \" קדימה\",\n",
            "        \"start_time\": \"0:00:12.840000\",\n",
            "        \"end_time\": \"0:00:13.460000\",\n",
            "        \"world_time\": \"15:38:47.462\",\n",
            "        \"simulation_time\": 258.46668014690005,\n",
            "        \"end_simulation_time\": 259.08668014690005\n",
            "    },\n",
            "    {\n",
            "        \"text\": \" פאק\",\n",
            "        \"start_time\": \"0:00:13.940000\",\n",
            "        \"end_time\": \"0:00:14.360000\",\n",
            "        \"world_time\": \"15:38:48.549\",\n",
            "        \"simulation_time\": 259.2000135184801,\n",
            "        \"end_simulation_time\": 259.6200135184801\n",
            "    },\n",
            "    {\n",
            "        \"text\": \" חכה\",\n",
            "        \"start_time\": \"0:00:14.360000\",\n",
            "        \"end_time\": \"0:00:15.220000\",\n",
            "        \"world_time\": \"15:38:48.968\",\n",
            "        \"simulation_time\": 259.5000135341265,\n",
            "        \"end_simulation_time\": 260.3600135341265\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## combine through tsv file"
      ],
      "metadata": {
        "id": "qOKgFu3UtkPu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yKfRb4N2mG0C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}